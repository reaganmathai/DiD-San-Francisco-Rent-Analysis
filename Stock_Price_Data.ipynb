{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ1ALQ7NNxdJsXYh7ZDDPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reaganmathai/DiD-San-Francisco-Rent-Analysis/blob/main/Stock_Price_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1LrkUQQjotn",
        "outputId": "8a5911db-52ae-4ec7-8695-f2a14a1572b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define paths\n",
        "current_directory = os.getcwd()\n",
        "input_file_path = os.path.join(current_directory, 'FinalDatabase.csv')  # Input file location\n",
        "output_file_path = os.path.join(current_directory, 'SentimentDispersion.csv')  # Output file location\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/FinalStockDatabase.csv')\n",
        "\n",
        "# Convert date columns to datetime format, correcting the format to match your data\n",
        "df['date'] = pd.to_datetime(df['date'], format='%d%b%Y')  # Corrected format here\n",
        "df['rdq'] = pd.to_datetime(df['rdq'], format='%d%b%Y')    # Corrected format here\n",
        "\n",
        "# Define the period before the earnings announcement date (e.g., B0 = 10 days, B1 = 5 days before)\n",
        "B0 = 10  # Start of the period (10 days before)\n",
        "B1 = 5   # End of the period (5 days before)\n",
        "\n",
        "# Prepare a list to collect results\n",
        "results = []\n",
        "\n",
        "# Iterate over each firm\n",
        "for firm_id in df['firm_id'].unique():\n",
        "    firm_data = df[df['firm_id'] == firm_id]\n",
        "\n",
        "    # Iterate over each earnings announcement date for the firm\n",
        "    for rdq in firm_data['rdq'].dropna().unique():  # Ensure rdq is not NaT\n",
        "        # Select the data from B0 to B1 days before the announcement\n",
        "        period_start = rdq - pd.Timedelta(days=B0)\n",
        "        period_end = rdq - pd.Timedelta(days=B1)\n",
        "        period_data = firm_data[(firm_data['date'] >= period_start) & (firm_data['date'] < period_end)]\n",
        "\n",
        "        # Calculate sentiment range and standard deviation, ignoring NaN values\n",
        "        if not period_data.empty:\n",
        "            max_sentiment = period_data['sentiment'].max(skipna=True)\n",
        "            min_sentiment = period_data['sentiment'].min(skipna=True)\n",
        "            sentiment_range = max_sentiment - min_sentiment if pd.notnull(max_sentiment) and pd.notnull(min_sentiment) else None\n",
        "            sentiment_std = period_data['sentiment'].std(skipna=True)\n",
        "        else:\n",
        "            sentiment_range = None\n",
        "            sentiment_std = None\n",
        "\n",
        "        # Collect results\n",
        "        results.append({\n",
        "            'firm_id': firm_id,\n",
        "            'rdq': rdq,\n",
        "            'sentiment_range': sentiment_range,\n",
        "            'sentiment_std': sentiment_std\n",
        "        })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Sentiment dispersion data saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnMfGnC8S23Q",
        "outputId": "5bbca7e2-34e9-4797-fc4c-83c4c1796c02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b710e4e429fd>:10: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/FinalStockDatabase.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment dispersion data saved to /content/SentimentDispersion.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pandas.tseries.offsets import BDay\n",
        "\n",
        "data = pd.read_csv('/content/FinalStockDatabase.csv')\n",
        "\n",
        "# Define your constants for business days before and after the report date (RDQ)\n",
        "D0 = 5  # Days before the earnings announcement\n",
        "D1 = 5  # Days after the earnings announcement\n",
        "\n",
        "# Iterate over each unique firm\n",
        "\n",
        "# Convert 'date' column to datetime\n",
        "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
        "\n",
        "# Drop rows where 'date' or 'price' is NaN\n",
        "data.dropna(subset=['date', 'price'], inplace=True)\n",
        "\n",
        "# Ensure data is sorted by date for each firm_id\n",
        "data.sort_values(by=['firm_id', 'date'], inplace=True)\n",
        "\n",
        "# Calculate daily returns for each firm\n",
        "data['daily_return'] = data.groupby('firm_id')['price'].pct_change()\n",
        "\n",
        "# Calculate the average daily return for each firm\n",
        "average_daily_returns = data.groupby('firm_id')['daily_return'].mean()\n",
        "\n",
        "# Convert the average daily returns to a DataFrame and reset the index for easier reading\n",
        "average_daily_returns_df = average_daily_returns.reset_index()\n",
        "\n",
        "# Give the columns meaningful names\n",
        "average_daily_returns_df.columns = ['firm_id', 'average_daily_return']\n",
        "\n",
        "# Display the average daily returns for each firm\n",
        "print(average_daily_returns_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2rZN7plhx5T",
        "outputId": "7678de53-4dd0-47b1-9746-67bba4f3a8db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-7c877321c36c>:4: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/FinalStockDatabase.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      firm_id  average_daily_return\n",
            "0           3              0.001575\n",
            "1           4              0.000968\n",
            "2          11              0.001006\n",
            "3          14              0.010243\n",
            "4          15              0.000110\n",
            "...       ...                   ...\n",
            "3023    10838              0.000032\n",
            "3024    10839             -0.000006\n",
            "3025    10842              0.001094\n",
            "3026    10847              0.001093\n",
            "3027    10848              0.000972\n",
            "\n",
            "[3028 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4/1"
      ],
      "metadata": {
        "id": "cmR38QfgNhqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "\n",
        "def calculate_adjusted_daily_returns(input_file_path, D0, D1, output_file_path):\n",
        "    # Load and prepare the data\n",
        "    data = pd.read_csv('/content/FinalStockDatabase.csv')  # Make sure you're loading the correct file. Previously, it was hardcoded to '/content/SentimentDispersion.csv'.\n",
        "\n",
        "    # First, check the column names to ensure 'date' and 'rdq' are present\n",
        "    print(data.columns)  # This will print out all column names. Ensure there's 'date' and 'rdq'.\n",
        "\n",
        "    # Ensuring correct datetime format and coercing errors\n",
        "    # Make sure your CSV file has a 'date' and 'rdq' column. If the column names are different, you'll need to adjust them here.\n",
        "    data['date'] = pd.to_datetime(data['date'], errors='coerce', format='%d%b%Y')\n",
        "    data['rdq'] = pd.to_datetime(data['rdq'], errors='coerce', format='%d%b%Y')\n",
        "\n",
        "    # Dropping rows where either date or price is NaN to ensure clean data\n",
        "    data.dropna(subset=['date', 'price', 'rdq'], inplace=True)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for firm_id in data['firm_id'].unique():\n",
        "        firm_data = data[data['firm_id'] == firm_id].sort_values('date')\n",
        "\n",
        "        for rdq in firm_data['rdq'].unique():\n",
        "            rdq_date = pd.to_datetime(rdq)\n",
        "            start_date = rdq_date - BDay(D0)\n",
        "            end_date = rdq_date + BDay(D1)\n",
        "\n",
        "            adjusted_start_date = firm_data[(firm_data['date'] <= start_date)].dropna(subset=['price']).iloc[-1]['date'] if not firm_data[(firm_data['date'] <= start_date)].empty else None\n",
        "            adjusted_end_date = firm_data[(firm_data['date'] >= end_date)].dropna(subset=['price']).iloc[0]['date'] if not firm_data[(firm_data['date'] >= end_date)].empty else None\n",
        "\n",
        "            if adjusted_start_date is not None and adjusted_end_date is not None:\n",
        "                price_start = firm_data[firm_data['date'] == adjusted_start_date]['price'].values[0]\n",
        "                price_end = firm_data[firm_data['date'] == adjusted_end_date]['price'].values[0]\n",
        "                days = (adjusted_end_date - adjusted_start_date).days\n",
        "\n",
        "                stock_return = ((price_end - price_start) / price_start) / days if days > 0 else 0\n",
        "\n",
        "                results.append({\n",
        "                    'firm_id': firm_id,\n",
        "                    'rdq': rdq,\n",
        "                    'daily_return': stock_return,\n",
        "                    'adjusted_start_date': adjusted_start_date.strftime('%Y-%m-%d'),\n",
        "                    'adjusted_end_date': adjusted_end_date.strftime('%Y-%m-%d'),\n",
        "                    'days': days\n",
        "                })\n",
        "\n",
        "    # Converting results into a DataFrame and saving to CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(output_file_path, index=False)\n",
        "    print(f\"Results saved to {output_file_path}\")\n",
        "\n",
        "# Ensure you have the correct file paths\n",
        "current_directory = os.getcwd()\n",
        "input_file_path = os.path.join(current_directory, 'FinalDatabase.csv')  # Ensure this matches the file you intend to process\n",
        "output_file_path = os.path.join(current_directory, 'AdjustedDailyReturns.csv')\n",
        "D0 = 2  # Days before the earnings announcement\n",
        "D1 = 5  # Days after the earnings announcement\n",
        "\n",
        "# Before running the function, make sure you've corrected any discrepancies in column names or file paths.\n",
        "calculate_adjusted_daily_returns(input_file_path, D0, D1, output_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYuXAValNd9v",
        "outputId": "32c9ca72-a1fb-4e1b-cc0f-04275c12d41f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-9d609a8519f8>:7: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/FinalStockDatabase.csv')  # Make sure you're loading the correct file. Previously, it was hardcoded to '/content/SentimentDispersion.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['date', 'price', 'firm_id', 'sentiment', 'Systematic_Risk',\n",
            "       'Idiosyncratic_Risk', 'rdq', 'Interest_Coverage', 'Dividend_Payer',\n",
            "       'RF', 'mktcap', 'Size'],\n",
            "      dtype='object')\n",
            "Results saved to /content/AdjustedDailyReturns.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "sentiment_df = pd.read_csv('SentimentDispersion.csv')\n",
        "returns_df = pd.read_csv('AdjustedDailyReturns.csv')\n",
        "\n",
        "# Merge the datasets on 'firm_id' and 'rdq'\n",
        "merged_df = pd.merge(sentiment_df, returns_df, on=['firm_id', 'rdq'])\n",
        "\n",
        "# Drop rows with missing values\n",
        "cleaned_df = merged_df.dropna()\n",
        "\n",
        "# Optionally, inspect the cleaned data\n",
        "print(cleaned_df.head())\n",
        "\n",
        "# Save the cleaned dataframe to a new CSV file\n",
        "cleaned_df.to_csv('Portfolio.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFLuAT_3REre",
        "outputId": "8d4fab20-0d36-448b-843d-953195aa2dbf",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     firm_id         rdq  sentiment_range  sentiment_std  daily_return  \\\n",
            "101      210  2010-05-18          0.04400       0.031113     -0.010510   \n",
            "479      891  2010-04-22          0.00565       0.003995     -0.001903   \n",
            "481      891  2010-10-21          0.00380       0.002687      0.005721   \n",
            "565     1016  2010-08-06          0.00510       0.002944     -0.009301   \n",
            "566     1016  2010-11-05          1.79740       0.851592     -0.004488   \n",
            "\n",
            "    adjusted_start_date adjusted_end_date  days  \n",
            "101          2010-05-14        2010-05-25    11  \n",
            "479          2010-04-20        2010-04-29     9  \n",
            "481          2010-10-19        2010-10-28     9  \n",
            "565          2010-08-04        2010-08-13     9  \n",
            "566          2010-11-03        2010-11-12     9  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/FinalStockDatabase.csv')\n",
        "\n",
        "# Convert 'date' and 'rdq' columns to datetime format\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df['rdq'] = pd.to_datetime(df['rdq'], errors='coerce')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfDR4a-UtsZB",
        "outputId": "38e56ddd-b42f-448d-f300-2f543e665d94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-782d91f4e144>:4: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/FinalStockDatabase.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.offsets import BDay\n",
        "\n",
        "# Assume B0 and B1 based on your benchmark scenario\n",
        "B0, B1 = 9, 2\n",
        "\n",
        "# Prepare a DataFrame to store results\n",
        "results = []\n",
        "\n",
        "for firm_id in df['firm_id'].unique():\n",
        "    firm_data = df[df['firm_id'] == firm_id].sort_values(by='date')\n",
        "    for rdq in firm_data['rdq'].unique():\n",
        "        period_start = rdq - BDay(B0)\n",
        "        period_end = rdq - BDay(B1)\n",
        "        period_data = firm_data[(firm_data['date'] >= period_start) & (firm_data['date'] <= period_end)]\n",
        "\n",
        "        sentiment_range = period_data['sentiment'].max() - period_data['sentiment'].min() if not period_data.empty else None\n",
        "        sentiment_std = period_data['sentiment'].std() if not period_data.empty else None\n",
        "\n",
        "        results.append({\n",
        "            'firm_id': firm_id,\n",
        "            'rdq': rdq,\n",
        "            'sentiment_range': sentiment_range,\n",
        "            'sentiment_std': sentiment_std\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "GbtUtTtkt4aS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D0, D1 = 2, 5\n",
        "\n",
        "returns = []\n",
        "\n",
        "for firm_id in df['firm_id'].unique():\n",
        "    firm_data = df[df['firm_id'] == firm_id].sort_values(by='date')\n",
        "    for rdq in firm_data['rdq'].unique():\n",
        "        start_date = rdq - BDay(D0)\n",
        "        end_date = rdq + BDay(D1)\n",
        "\n",
        "        # Ensure the dates are within the data's range\n",
        "        if firm_data['date'].min() <= start_date <= firm_data['date'].max() and firm_data['date'].min() <= end_date <= firm_data['date'].max():\n",
        "            start_price = firm_data[firm_data['date'] == start_date]['price'].iloc[0]\n",
        "            end_price = firm_data[firm_data['date'] == end_date]['price'].iloc[0]\n",
        "            stock_return = (end_price - start_price) / start_price\n",
        "\n",
        "            returns.append({\n",
        "                'firm_id': firm_id,\n",
        "                'rdq': rdq,\n",
        "                'stock_return': stock_return\n",
        "            })\n",
        "\n",
        "returns_df = pd.DataFrame(returns)"
      ],
      "metadata": {
        "id": "vrLU4M-3uB7I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where 'sentiment_range' is NaN to ensure clean data for processing\n",
        "cleaned_df = merged_df.dropna(subset=['sentiment_range'])\n",
        "\n",
        "# Determine the quantiles including NaN handling\n",
        "quantiles = cleaned_df['sentiment_range'].quantile([0.2, 0.4, 0.6, 0.8]).tolist()\n",
        "\n",
        "# Define a function to manually categorize data into quintiles\n",
        "def categorize_into_quintiles(value, boundaries):\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "    for i, boundary in enumerate(boundaries):\n",
        "        if value <= boundary:\n",
        "            return i\n",
        "    return len(boundaries)\n",
        "\n",
        "# Apply the categorization\n",
        "cleaned_df['quintile'] = cleaned_df['sentiment_range'].apply(lambda x: categorize_into_quintiles(x, quantiles))\n",
        "\n",
        "# Now, calculate portfolio returns based on these manually categorized quintiles\n",
        "portfolio_returns = cleaned_df.groupby('quintile')['stock_return'].mean().reset_index()\n",
        "\n",
        "print(portfolio_returns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhH9BmG1uLty",
        "outputId": "e39378ca-de6f-4804-fd8c-a132ade0b86b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   quintile  stock_return\n",
            "0         0     -0.005457\n",
            "1         2     -0.022080\n",
            "2         3     -0.013683\n",
            "3         4     -0.013243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-e8aeab6c127d>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cleaned_df['quintile'] = cleaned_df['sentiment_range'].apply(lambda x: categorize_into_quintiles(x, quantiles))\n"
          ]
        }
      ]
    }
  ]
}