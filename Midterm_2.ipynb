{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9LXOHXJJFPFfKdPDkTcQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reaganmathai/DiD-San-Francisco-Rent-Analysis/blob/main/Midterm_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3\n"
      ],
      "metadata": {
        "id": "2h_J1IuoloCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Downloading Financial Data using yfinance: Analyze “AAPL” stock perfor- mance over the last five years.\n",
        "(a) Write Python code using the yfinance library to download daily stock prices of “AAPL” for the past five years.\n",
        "(b) Write a brief ChatGPT prompt to request guidance or explanation on how to use the yfinance library for downloading stock data."
      ],
      "metadata": {
        "id": "1hinW6Sbl-l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1a"
      ],
      "metadata": {
        "id": "1uFECd_svRSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Download Apple's stock data for the past 5 years\n",
        "apple_stock = yf.Ticker(\"AAPL\")\n",
        "apple_data = apple_stock.history(period=\"5y\")\n",
        "\n",
        "# Save the data to a CSV file\n",
        "apple_data.to_csv('AAPL_5y_stock_data.csv')"
      ],
      "metadata": {
        "id": "hkwsWrhvmD5C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1b"
      ],
      "metadata": {
        "id": "QASvedLqvUHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1b. Please write me code in python using the library yfinance to download the daily stock prices of AAPL over the past 5 years and save it to a csv file."
      ],
      "metadata": {
        "id": "nBhe1r_EmYKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Data Manipulation and Conversion: Given economic data.csv with columns for Country, Year, GDP, InflationRate, and UnemploymentRate.\n",
        "(a) Use pandas to read the CSV file and fill missing values with the column means.\n",
        "(b) Write a brief ChatGPT prompt to request assistance on handling missing data\n",
        "in pandas."
      ],
      "metadata": {
        "id": "SOJwLYNUmEek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2a"
      ],
      "metadata": {
        "id": "JD7eOKrosaaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to scrape tables from Wikipedia and return a DataFrame\n",
        "def scrape_table(url, column_mappings):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML and find the first table\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table = soup.find('table', {'class': 'wikitable'})\n",
        "        df = pd.read_html(str(table), header=0)[0]\n",
        "\n",
        "        # Rename columns according to provided mappings\n",
        "        df.rename(columns=column_mappings, inplace=True)\n",
        "\n",
        "        # Check if 'Country' column exists, if not try to match any column containing 'Country'\n",
        "        if 'Country' not in df.columns:\n",
        "            country_columns = [col for col in df.columns if 'Country' in col]\n",
        "            if country_columns:\n",
        "                df.rename(columns={country_columns[0]: 'Country'}, inplace=True)\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data from {url}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# URLs for Wikipedia pages with economic data tables\n",
        "gdp_url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
        "inflation_url = 'https://en.wikipedia.org/wiki/List_of_countries_by_inflation_rate'\n",
        "unemployment_url = 'https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate'\n",
        "\n",
        "# Column mappings for each table\n",
        "gdp_columns_mapping = {'Nominal GDP': 'GDP'}\n",
        "inflation_columns_mapping = {'Inflation rate (CPI)': 'InflationRate'}\n",
        "unemployment_columns_mapping = {'Unemployment rate': 'UnemploymentRate'}\n",
        "\n",
        "# Scrape the tables from Wikipedia\n",
        "gdp_df = scrape_table(gdp_url, gdp_columns_mapping)\n",
        "inflation_df = scrape_table(inflation_url, inflation_columns_mapping)\n",
        "unemployment_df = scrape_table(unemployment_url, unemployment_columns_mapping)\n",
        "\n",
        "# Merge the DataFrames on the 'Country' column\n",
        "economic_data_df = gdp_df.merge(inflation_df, on='Country', how='outer')\n",
        "economic_data_df = economic_data_df.merge(unemployment_df, on='Country', how='outer')\n",
        "\n",
        "# Fill missing values with the mean of the columns\n",
        "economic_data_df.fillna(economic_data_df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Save the merged DataFrame to a CSV file\n",
        "economic_data_df.to_csv('economic_data.csv', index=False)\n",
        "\n",
        "print(\"The economic_data.csv file has been created with the following data:\")\n",
        "print(economic_data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJXKNKvMaC0v",
        "outputId": "cc1ecfbf-b521-4629-eb00-7459aced7f55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economic_data.csv file has been created with the following data:\n",
            "             Country  UN region IMF[1][13] IMF[1][13].1 World Bank[14]  \\\n",
            "0  Country/Territory  UN region   Forecast         Year       Estimate   \n",
            "1              World          —  109529216         2024      100562011   \n",
            "2      United States   Americas   28781083         2024       25462700   \n",
            "3              China       Asia   18532633    2024[n 1]       17963171   \n",
            "4            Germany     Europe    4591100         2024        4072192   \n",
            "\n",
            "  World Bank[14].1 United Nations[15] United Nations[15].1  \\\n",
            "0             Year           Estimate                 Year   \n",
            "1             2022           96698005                 2021   \n",
            "2             2022           23315081                 2021   \n",
            "3        2022[n 3]           17734131            2021[n 1]   \n",
            "4             2022            4259935                 2021   \n",
            "\n",
            "  World Bank consumer price indices (in %)  \\\n",
            "0                                      NaN   \n",
            "1                                      NaN   \n",
            "2                                     1.64   \n",
            "3                                     3.18   \n",
            "4                                     1.10   \n",
            "\n",
            "  World Bank consumer price indices (in %).1  ...  \\\n",
            "0                                        NaN  ...   \n",
            "1                                        NaN  ...   \n",
            "2                                       3.16  ...   \n",
            "3                                       5.55  ...   \n",
            "4                                       2.08  ...   \n",
            "\n",
            "  World Bank consumer price indices (in %).7  \\\n",
            "0                                        NaN   \n",
            "1                                        NaN   \n",
            "2                                       2.13   \n",
            "3                                       1.59   \n",
            "4                                       1.51   \n",
            "\n",
            "  World Bank consumer price indices (in %).8  \\\n",
            "0                                        NaN   \n",
            "1                                        NaN   \n",
            "2                                       2.44   \n",
            "3                                       2.07   \n",
            "4                                       1.73   \n",
            "\n",
            "  World Bank consumer price indices (in %).9  \\\n",
            "0                                        NaN   \n",
            "1                                        NaN   \n",
            "2                                       1.81   \n",
            "3                                       2.90   \n",
            "4                                       1.45   \n",
            "\n",
            "  World Bank consumer price indices (in %).10  \\\n",
            "0                                         NaN   \n",
            "1                                         NaN   \n",
            "2                                        1.23   \n",
            "3                                        2.42   \n",
            "4                                        0.14   \n",
            "\n",
            "  World Bank consumer price indices (in %).11  \\\n",
            "0                                         NaN   \n",
            "1                                         NaN   \n",
            "2                                        4.70   \n",
            "3                                        0.98   \n",
            "4                                        3.07   \n",
            "\n",
            "  World Bank consumer price indices (in %).12  \\\n",
            "0                                         NaN   \n",
            "1                                         NaN   \n",
            "2                                        8.00   \n",
            "3                                        1.97   \n",
            "4                                        6.87   \n",
            "\n",
            "  WB Consumer price index  (2010=100) WB Consumer price index  (2010=100).1  \\\n",
            "0                                 NaN                                   NaN   \n",
            "1                                 NaN                                   NaN   \n",
            "2                               134.2                                  2022   \n",
            "3                               131.9                                  2022   \n",
            "4                               124.5                                  2022   \n",
            "\n",
            "  Unemployment rate (%) Source/date of information  \n",
            "0              7.937578                        NaN  \n",
            "1              7.937578                        NaN  \n",
            "2              7.937578                        NaN  \n",
            "3              7.937578                        NaN  \n",
            "4              7.937578                        NaN  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2b"
      ],
      "metadata": {
        "id": "6M4KT0UAsYAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " b) I am working with pandas to handle missing data in a dataset. Could you provide me with the general code to manage missing values and replace it with the column means effectively in a pandas DataFrame?"
      ],
      "metadata": {
        "id": "Ogbom9Yv0vkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Visualization and Summary Statistics: You have GDP growth rates for various\n",
        "countries.\n",
        "(a) Create a line plot for “Country A” and “Country B” GDP growth over the\n",
        "last decade using matplotlib or seaborn.\n",
        "(b) Calculate and display the mean, median, and standard deviation of GDP\n",
        "growth rates.\n",
        "(c) Write a brief ChatGPT prompt to request assistance on creating visualizations\n",
        "with matplotlib or seaborn."
      ],
      "metadata": {
        "id": "vrRbBf3amHAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3a & 3b"
      ],
      "metadata": {
        "id": "5R_x_UupshMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the economic data\n",
        "df = pd.read_csv('/content/economic_data.csv')\n",
        "\n",
        "# Rename the GDP column for easier access\n",
        "df.rename(columns={'IMF[1][13]': 'GDP'}, inplace=True)\n",
        "\n",
        "# If the 'Year' column is actually named differently, we need to rename it appropriately\n",
        "# Assuming that 'IMF[1][13].1' column is the 'Year' column, we'll rename it to 'Year'\n",
        "df.rename(columns={'IMF[1][13].1': 'Year'}, inplace=True)\n",
        "\n",
        "# Convert 'Year' to an integer type if it's not already\n",
        "# This is required for sorting and selecting the largest values properly\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "df.dropna(subset=['Year'], inplace=True)  # Drop rows where Year could not be converted to a number\n",
        "df['Year'] = df['Year'].astype(int)\n",
        "\n",
        "# Filter the DataFrame for 'United States' and 'India'\n",
        "df_usa = df[df['Country'] == 'United States']\n",
        "df_india = df[df['Country'] == 'India']\n",
        "\n",
        "# Extracting GDP data for the last decade for both countries\n",
        "# Since the dataset might contain more years, we're selecting the 10 most recent ones\n",
        "df_usa = df_usa.nlargest(10, 'Year')\n",
        "df_india = df_india.nlargest(10, 'Year')\n",
        "\n",
        "# Plotting the GDP for both countries using seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_usa, x='Year', y='GDP', label='United States', marker='o')\n",
        "sns.lineplot(data=df_india, x='Year', y='GDP', label='India', marker='o')\n",
        "plt.title('GDP Over the Last Decade for the United States and India')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('GDP (US$MM)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display the statistics for the GDP\n",
        "print(\"United States GDP Statistics:\")\n",
        "print(df_usa['GDP'].describe())\n",
        "\n",
        "print(\"\\nIndia GDP Statistics:\")\n",
        "print(df_india['GDP'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "D68af84ykutp",
        "outputId": "2c9c750e-ef22-45c1-f27c-2e6e4fe7b08f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States GDP Statistics:\n",
            "count            1\n",
            "unique           1\n",
            "top       28781083\n",
            "freq             1\n",
            "Name: GDP, dtype: object\n",
            "\n",
            "India GDP Statistics:\n",
            "count           1\n",
            "unique          1\n",
            "top       3937011\n",
            "freq            1\n",
            "Name: GDP, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*****After running this code I have realized that my data set does not pull enough information on the GDP over the years. I would really love to understand how to fix this issue however the colab in the appendix of the textbook that describes how to download data is blank! How am I supposed to know how to execute the if I have no text or code to reference! Just make it up? I have decided to just display this data and show you that I can indeed source data and create a dataframe from it, however I do understand that there is more data needed."
      ],
      "metadata": {
        "id": "ml6gZHqQm0Ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3c"
      ],
      "metadata": {
        "id": "IE8hqAAqslzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please generate me code to accomplish this using matplotlib or seaborn. Let Country A be America and let country B be India. Using the economic_data.csv file that we created in the last question, create me the code to plot the line of GDP growth for both countries. Also Calculate and display the mean, median, and standard deviation of GDP growth rates."
      ],
      "metadata": {
        "id": "DXtOV2xdszMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Estimating Econometric Models: Use panel data.csv with variables: Coun-\n",
        "try, Year, PolicyChange, OutcomeVariable.\n",
        "(a) Describe an IV approach to estimate the impact of PolicyChange on Out- comeVariable using Python.\n",
        "(b) Explain estimating a Difference-in-Differences (DiD) model, identifying treat- ment and control groups.\n",
        "(c) Write a brief ChatGPT prompt for guidance on implementing IV and DiD models in Python."
      ],
      "metadata": {
        "id": "VmweZ_TYmJvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4a"
      ],
      "metadata": {
        "id": "UWp2I0XwsGHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from linearmodels.iv import IV2SLS\n",
        "from statsmodels.api import add_constant\n",
        "\n",
        "# Let's assume you have a DataFrame `df` with the following columns:\n",
        "# 'dependent_var' : The dependent variable\n",
        "# 'endogenous_var': The endogenous variable\n",
        "# 'instrument'    : The instrument variable\n",
        "# 'exogenous_vars': Other exogenous control variables\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('path_to_your_data.csv')\n",
        "\n",
        "# Add a constant term to the exogenous variables if needed\n",
        "df['constant'] = 1\n",
        "\n",
        "# Define the variables for the model\n",
        "dependent = df['dependent_var']\n",
        "endog = df['endogenous_var']\n",
        "exog = df[['constant'] + 'exogenous_vars']\n",
        "instr = df['instrument']\n",
        "\n",
        "# Step 1: Run the first stage regression of the endogenous variable on the instrument\n",
        "first_stage = IV2SLS(dependent=endog, exog=add_constant(exog), instrument=instr).fit()\n",
        "\n",
        "# Get the predicted values of the endogenous variable\n",
        "df['endog_predicted'] = first_stage.fitted_values\n",
        "\n",
        "# Step 2: Run the second stage regression of the dependent variable on the predicted values\n",
        "iv_model = IV2SLS(dependent=dependent, exog=add_constant(exog), endog=df['endog_predicted'], instrument=instr).fit()\n",
        "\n",
        "# Print the results of the IV estimation\n",
        "print(iv_model.summary())\n",
        "\n",
        "#Double Lasso Regression\n",
        "# Standardize your confounders (features)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df[confounders])\n",
        "\n",
        "# Step 1: Lasso regression to select variables related to the treatment\n",
        "lasso_treatment = LassoCV(cv=5, random_state=0).fit(X, df['treatment'])\n",
        "\n",
        "# Select the features where the coefficient has not been shrunk to zero\n",
        "selected_features_treatment = [f for f, s in zip(confounders, lasso_treatment.coef_ != 0) if s]\n",
        "\n",
        "# Step 2: Lasso regression to select variables related to the outcome\n",
        "lasso_outcome = LassoCV(cv=5, random_state=0).fit(X, df['outcome'])\n",
        "\n",
        "# Select the features where the coefficient has not been shrunk to zero\n",
        "selected_features_outcome = [f for f, s in zip(confounders, lasso_outcome.coef_ != 0) if s]\n",
        "\n",
        "# Combine the selected features from both lasso regressions\n",
        "selected_features = list(set(selected_features_treatment + selected_features_outcome))\n",
        "\n",
        "# Step 3: OLS regression with the selected features to estimate the causal effect\n",
        "X_selected = df[selected_features]\n",
        "X_selected = add_constant(X_selected)  # Add a constant term\n",
        "model = OLS(df['outcome'], X_selected).fit()\n",
        "\n",
        "# Print the results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "yl7KGGt5mNgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps to an IV analysis are as follows:\n",
        "1. Identify the instrument (ensure it satisfies relevance and exogeneity with the double lasso)\n",
        "2. Load and Prepare the data into Python & upload the necessary libraries\n",
        "3. Define all variables\n",
        "4. Perform a first stage regression\n",
        "5. Perform a second stage regression\n",
        "6. Interpret your results"
      ],
      "metadata": {
        "id": "GjTCNExcs7JO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4b"
      ],
      "metadata": {
        "id": "NTWB2YgTvZN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from econml.dml import CausalForestDML\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('path_to_your_data.csv')\n",
        "\n",
        "# Assuming your dataset contains:\n",
        "# 'outcome': the dependent variable\n",
        "# 'date': the dates or periods of observations\n",
        "# 'group_id': identifier if the observation is treatment or control\n",
        "\n",
        "# Convert date to datetime and sort (if necessary)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.sort_values('date', inplace=True)\n",
        "\n",
        "# Define the treatment and control groups\n",
        "# Suppose you know the treatment started on a specific date and affected specific groups\n",
        "treatment_start_date = 'YYYY-MM-DD'  # replace with the actual start date of the treatment\n",
        "treatment_group_ids = [1, 2, 3]  # replace with actual IDs corresponding to treatment groups\n",
        "\n",
        "# Create the 'group' variable where 1 indicates treatment group and 0 indicates control\n",
        "df['group'] = df['group_id'].apply(lambda x: 1 if x in treatment_group_ids else 0)\n",
        "\n",
        "# Create the 'time' variable where 1 indicates post-treatment period and 0 indicates pre-treatment\n",
        "df['time'] = (df['date'] >= treatment_start_date).astype(int)\n",
        "\n",
        "# Create the interaction term for the DiD analysis\n",
        "df['treatment_time'] = df['group'] * df['time']\n",
        "\n",
        "# Check balance between groups before treatment\n",
        "pre_treatment = df[df['time'] == 0]\n",
        "post_treatment = df[df['time'] == 1]\n",
        "\n",
        "# Plotting to visualize outcomes before and after treatment\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "pre_treatment.groupby('group')['outcome'].mean().plot(kind='bar')\n",
        "plt.title('Average Outcome before Treatment')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Outcome')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "post_treatment.groupby('group')['outcome'].mean().plot(kind='bar')\n",
        "plt.title('Average Outcome after Treatment')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Outcome')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optionally, check for common trends assumption visually\n",
        "# Plot average outcomes over time by group\n",
        "(df.groupby(['date', 'group'])['outcome'].mean().unstack().plot(figsize=(10, 6), marker='o'))\n",
        "plt.title('Trends in Outcome by Group Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average Outcome')\n",
        "plt.legend(['Control', 'Treatment'])\n",
        "plt.show()\n",
        "\n",
        "# Fit the DiD regression model using statsmodels\n",
        "model = smf.ols('outcome ~ time + group + treatment_time', data=df).fit()\n",
        "\n",
        "# Print the results\n",
        "print(model.summary())\n",
        "\n",
        "# Save the prepared dataframe if needed\n",
        "df.to_csv('prepared_data_for_DiD.csv', index=False)\n",
        "\n",
        "# Ensure data types are correct, 'group' and 'time' should be binary (0 or 1)\n",
        "df['group'] = df['group'].astype(int)\n",
        "df['time'] = df['time'].astype(int)\n",
        "df['treatment_time'] = df['group'] * df['time']\n",
        "\n",
        "# Define the outcome, treatment and feature variables\n",
        "Y = df['outcome']  # Outcome variable\n",
        "T = df['treatment_time']  # Treatment variable (interaction term from DiD)\n",
        "X = df[['time', 'group']]  # Other covariates\n",
        "\n",
        "# Use Causal Forests to estimate the causal effect\n",
        "# Here we use LassoCV for the model_Y and GradientBoostingRegressor for model_T\n",
        "causal_forest = CausalForestDML(model_y=LassoCV(), model_t=GradientBoostingRegressor(),\n",
        "                                discrete_treatment=True, random_state=123)\n",
        "\n",
        "# Fit the model\n",
        "causal_forest.fit(Y, T, X=X)\n",
        "\n",
        "# Estimate the treatment effects\n",
        "treatment_effects = causal_forest.effect(X)\n",
        "\n",
        "# Calculate the average treatment effect\n",
        "average_treatment_effect = treatment_effects.mean()\n",
        "\n",
        "print(\"Estimated Average Treatment Effect:\", average_treatment_effect)\n",
        "\n",
        "# Optionally, plot the treatment effects\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(treatment_effects, bins=30, edgecolor='black')\n",
        "plt.title('Histogram of Individual Treatment Effects')\n",
        "plt.xlabel('Treatment Effect Size')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FC2oNnZbvYzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps to a DiD analysis are as follows\n",
        "\n",
        "1. Identify a treament and a control group\n",
        "2. Define the pre-treatment and post-treatment groups\n",
        "3. Collect the data and load it into python\n",
        "4. Define your variables (important!!)\n",
        "5. Estimate your model and incorportate a causal forest analysis to isolate the treatment effect\n",
        "6. Conclude your experiment by creating a statement of causal effects from the data."
      ],
      "metadata": {
        "id": "5fvScyqdvcxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4c\n"
      ],
      "metadata": {
        "id": "21Mc5shAw7Hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hey, I'm currently working on an econometrics project and need to estimate the causal effects of a policy intervention using Python. I would like to generate the code for two different research methods, IV and DiD. For IV (Instrumental Variables) (IV) my treatment variable might be endogenous. Could you guide me on how to implement an IV model using Python? I would like to set up the model using statsmodels or any other suitable library. Can you supplmement it with a double lasso test to ensure credibility. For Difference-in-Differences (DiD)I plan to analyze the effects of the policy over time and between two groups (treatment and control). How can I set up a DiD model in Python? Can you also generate code for the parallel trends assumption and the causal forests analysis."
      ],
      "metadata": {
        "id": "h4q-Ba9pw91c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Estimating an LSTM Model to Predict Stock Returns: Predict “AAPL” future stock returns using historical prices.\n",
        "(a) Outline preprocessing steps for LSTM modeling, mentioning specific transfor- mations or scaling.\n",
        "(b)Provide an overview of setting up and training an LSTM model with TensorFlow and Keras, including model architecture and techniques.\n",
        "(c) Write a brief ChatGPT prompt for guidance on LSTM model development and training with TensorFlow and Keras."
      ],
      "metadata": {
        "id": "l7UejaFvmN6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5a"
      ],
      "metadata": {
        "id": "1_UK2I1Cuz7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume 'AAPL_5y_stock_data.csv' contains historical stock price data for AAPL\n",
        "stock_data = pd.read_csv('AAPL_5y_stock_data.csv')\n",
        "\n",
        "# Preprocessing steps for LSTM modeling\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(stock_data['Close'].values.reshape(-1,1))\n",
        "\n",
        "# Assuming we are using a look-back period of 60 days for our predictions\n",
        "look_back = 60\n",
        "X, y = [], []\n",
        "for i in range(look_back, len(scaled_data)):\n",
        "    X.append(scaled_data[i-look_back:i, 0])\n",
        "    y.append(scaled_data[i, 0])\n",
        "X, y = np.array(X), np.array(y)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Building the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X, y, epochs=25, batch_size=32)\n",
        "\n",
        "# Save the model for future use\n",
        "model.save('AAPL_stock_prediction_model.h5')"
      ],
      "metadata": {
        "id": "yjy0beyOmP9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Fetch historical stock prices for AAPL\n",
        "ticker = 'AAPL'\n",
        "data = yf.download(ticker, start='2010-01-01', end='2023-01-01')\n",
        "close_prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the closing prices\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(close_prices)\n",
        "\n",
        "# Create time-series sequences\n",
        "def create_sequences(data, sequence_length):\n",
        "    X, y = [], []\n",
        "    for i in range(sequence_length, len(data)):\n",
        "        X.append(data[i-sequence_length:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "sequence_length = 60  # Lookback period\n",
        "X, y = create_sequences(scaled_data, sequence_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9oP5p9JWRrG",
        "outputId": "f37cd88e-89c0-406e-cc5d-c812ef112971"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 a\n",
        "1. Fetch historical stock prices for AAPL using yfinance.\n",
        "2. Normalize the closing prices to a range between 0 and 1 using MinMaxScaler.\n",
        "3. Create time-series sequences that will serve as input for the LSTM model."
      ],
      "metadata": {
        "id": "YLvKSZ4lWW2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Define LSTM model architecture\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SwlRhwoWa1X",
        "outputId": "3920ec11-c8fe-4fd6-bde1-55e539182d1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "81/81 [==============================] - 13s 74ms/step - loss: 0.0013 - val_loss: 0.0036\n",
            "Epoch 2/100\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 3.3667e-04 - val_loss: 0.0021\n",
            "Epoch 3/100\n",
            "81/81 [==============================] - 5s 66ms/step - loss: 2.7184e-04 - val_loss: 0.0033\n",
            "Epoch 4/100\n",
            "81/81 [==============================] - 8s 97ms/step - loss: 2.5564e-04 - val_loss: 0.0039\n",
            "Epoch 5/100\n",
            "81/81 [==============================] - 5s 67ms/step - loss: 2.3442e-04 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "81/81 [==============================] - 7s 86ms/step - loss: 1.8921e-04 - val_loss: 0.0013\n",
            "Epoch 7/100\n",
            "81/81 [==============================] - 6s 71ms/step - loss: 1.8161e-04 - val_loss: 0.0019\n",
            "Epoch 8/100\n",
            "81/81 [==============================] - 7s 83ms/step - loss: 1.7562e-04 - val_loss: 9.2238e-04\n",
            "Epoch 9/100\n",
            "81/81 [==============================] - 5s 68ms/step - loss: 1.8184e-04 - val_loss: 0.0018\n",
            "Epoch 10/100\n",
            "81/81 [==============================] - 7s 86ms/step - loss: 1.7975e-04 - val_loss: 8.3446e-04\n",
            "Epoch 11/100\n",
            "81/81 [==============================] - 6s 76ms/step - loss: 1.5841e-04 - val_loss: 0.0025\n",
            "Epoch 12/100\n",
            "81/81 [==============================] - 6s 74ms/step - loss: 1.7178e-04 - val_loss: 0.0028\n",
            "Epoch 13/100\n",
            "81/81 [==============================] - 6s 69ms/step - loss: 1.4656e-04 - val_loss: 0.0022\n",
            "Epoch 14/100\n",
            "81/81 [==============================] - 8s 104ms/step - loss: 1.7595e-04 - val_loss: 7.9620e-04\n",
            "Epoch 15/100\n",
            "81/81 [==============================] - 10s 122ms/step - loss: 1.2896e-04 - val_loss: 0.0011\n",
            "Epoch 16/100\n",
            "81/81 [==============================] - 8s 93ms/step - loss: 1.3866e-04 - val_loss: 0.0028\n",
            "Epoch 17/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 1.3464e-04 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "81/81 [==============================] - 8s 94ms/step - loss: 1.1451e-04 - val_loss: 9.0967e-04\n",
            "Epoch 19/100\n",
            "81/81 [==============================] - 7s 88ms/step - loss: 1.2376e-04 - val_loss: 0.0011\n",
            "Epoch 20/100\n",
            "81/81 [==============================] - 5s 65ms/step - loss: 1.0897e-04 - val_loss: 7.5109e-04\n",
            "Epoch 21/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 1.2635e-04 - val_loss: 0.0031\n",
            "Epoch 22/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 1.1951e-04 - val_loss: 7.8458e-04\n",
            "Epoch 23/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 1.1285e-04 - val_loss: 9.3322e-04\n",
            "Epoch 24/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 1.3011e-04 - val_loss: 0.0020\n",
            "Epoch 25/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 1.0940e-04 - val_loss: 0.0011\n",
            "Epoch 26/100\n",
            "81/81 [==============================] - 6s 80ms/step - loss: 1.0410e-04 - val_loss: 8.7252e-04\n",
            "Epoch 27/100\n",
            "81/81 [==============================] - 7s 89ms/step - loss: 1.0710e-04 - val_loss: 0.0012\n",
            "Epoch 28/100\n",
            "81/81 [==============================] - 7s 91ms/step - loss: 1.1468e-04 - val_loss: 0.0011\n",
            "Epoch 29/100\n",
            "81/81 [==============================] - 5s 67ms/step - loss: 1.1669e-04 - val_loss: 0.0012\n",
            "Epoch 30/100\n",
            "81/81 [==============================] - 6s 73ms/step - loss: 1.0931e-04 - val_loss: 5.9547e-04\n",
            "Epoch 31/100\n",
            "81/81 [==============================] - 5s 64ms/step - loss: 1.0968e-04 - val_loss: 5.7332e-04\n",
            "Epoch 32/100\n",
            "81/81 [==============================] - 6s 80ms/step - loss: 1.0199e-04 - val_loss: 0.0010\n",
            "Epoch 33/100\n",
            "81/81 [==============================] - 6s 70ms/step - loss: 1.2283e-04 - val_loss: 0.0014\n",
            "Epoch 34/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 1.0760e-04 - val_loss: 5.5476e-04\n",
            "Epoch 35/100\n",
            "81/81 [==============================] - 6s 78ms/step - loss: 9.9667e-05 - val_loss: 5.9808e-04\n",
            "Epoch 36/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 9.8792e-05 - val_loss: 0.0022\n",
            "Epoch 37/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 1.0381e-04 - val_loss: 5.7841e-04\n",
            "Epoch 38/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 1.0078e-04 - val_loss: 0.0016\n",
            "Epoch 39/100\n",
            "81/81 [==============================] - 6s 80ms/step - loss: 9.4772e-05 - val_loss: 0.0012\n",
            "Epoch 40/100\n",
            "81/81 [==============================] - 5s 64ms/step - loss: 1.0299e-04 - val_loss: 5.3861e-04\n",
            "Epoch 41/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 9.5503e-05 - val_loss: 5.3164e-04\n",
            "Epoch 42/100\n",
            "81/81 [==============================] - 6s 74ms/step - loss: 1.0874e-04 - val_loss: 5.3960e-04\n",
            "Epoch 43/100\n",
            "81/81 [==============================] - 5s 60ms/step - loss: 9.9784e-05 - val_loss: 6.7028e-04\n",
            "Epoch 44/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 9.5054e-05 - val_loss: 9.2632e-04\n",
            "Epoch 45/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 1.0968e-04 - val_loss: 9.3586e-04\n",
            "Epoch 46/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 1.0727e-04 - val_loss: 5.1594e-04\n",
            "Epoch 47/100\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 9.7339e-05 - val_loss: 5.1241e-04\n",
            "Epoch 48/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 1.0040e-04 - val_loss: 6.5243e-04\n",
            "Epoch 49/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 9.8058e-05 - val_loss: 5.2229e-04\n",
            "Epoch 50/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 9.7447e-05 - val_loss: 6.7434e-04\n",
            "Epoch 51/100\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 9.6831e-05 - val_loss: 4.6657e-04\n",
            "Epoch 52/100\n",
            "81/81 [==============================] - 6s 68ms/step - loss: 1.0254e-04 - val_loss: 9.1490e-04\n",
            "Epoch 53/100\n",
            "81/81 [==============================] - 5s 64ms/step - loss: 1.0898e-04 - val_loss: 6.8843e-04\n",
            "Epoch 54/100\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 9.3214e-05 - val_loss: 5.9815e-04\n",
            "Epoch 55/100\n",
            "81/81 [==============================] - 7s 84ms/step - loss: 1.1168e-04 - val_loss: 0.0015\n",
            "Epoch 56/100\n",
            "81/81 [==============================] - 14s 169ms/step - loss: 8.9050e-05 - val_loss: 5.7581e-04\n",
            "Epoch 57/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 9.7370e-05 - val_loss: 0.0034\n",
            "Epoch 58/100\n",
            "81/81 [==============================] - 6s 76ms/step - loss: 1.0686e-04 - val_loss: 6.0027e-04\n",
            "Epoch 59/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 1.0169e-04 - val_loss: 5.2305e-04\n",
            "Epoch 60/100\n",
            "81/81 [==============================] - 5s 65ms/step - loss: 1.0485e-04 - val_loss: 8.9535e-04\n",
            "Epoch 61/100\n",
            "81/81 [==============================] - 6s 71ms/step - loss: 9.0235e-05 - val_loss: 5.9622e-04\n",
            "Epoch 62/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 1.0188e-04 - val_loss: 0.0014\n",
            "Epoch 63/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 1.2570e-04 - val_loss: 0.0011\n",
            "Epoch 64/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 9.6736e-05 - val_loss: 0.0019\n",
            "Epoch 65/100\n",
            "81/81 [==============================] - 6s 74ms/step - loss: 9.3227e-05 - val_loss: 0.0018\n",
            "Epoch 66/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 9.8720e-05 - val_loss: 0.0014\n",
            "Epoch 67/100\n",
            "81/81 [==============================] - 6s 70ms/step - loss: 9.1930e-05 - val_loss: 4.8889e-04\n",
            "Epoch 68/100\n",
            "81/81 [==============================] - 5s 66ms/step - loss: 1.0592e-04 - val_loss: 8.6204e-04\n",
            "Epoch 69/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 9.9389e-05 - val_loss: 4.4562e-04\n",
            "Epoch 70/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 9.6419e-05 - val_loss: 4.4262e-04\n",
            "Epoch 71/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 1.0113e-04 - val_loss: 0.0034\n",
            "Epoch 72/100\n",
            "81/81 [==============================] - 7s 84ms/step - loss: 1.0772e-04 - val_loss: 4.0513e-04\n",
            "Epoch 73/100\n",
            "81/81 [==============================] - 5s 65ms/step - loss: 9.6163e-05 - val_loss: 6.3790e-04\n",
            "Epoch 74/100\n",
            "81/81 [==============================] - 6s 73ms/step - loss: 1.0608e-04 - val_loss: 6.1394e-04\n",
            "Epoch 75/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 8.3490e-05 - val_loss: 6.1197e-04\n",
            "Epoch 76/100\n",
            "81/81 [==============================] - 5s 64ms/step - loss: 9.5009e-05 - val_loss: 5.6093e-04\n",
            "Epoch 77/100\n",
            "81/81 [==============================] - 6s 72ms/step - loss: 8.3701e-05 - val_loss: 3.9800e-04\n",
            "Epoch 78/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 8.9578e-05 - val_loss: 4.7731e-04\n",
            "Epoch 79/100\n",
            "81/81 [==============================] - 6s 74ms/step - loss: 8.7183e-05 - val_loss: 4.8900e-04\n",
            "Epoch 80/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 1.0344e-04 - val_loss: 7.8845e-04\n",
            "Epoch 81/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 1.0291e-04 - val_loss: 3.8197e-04\n",
            "Epoch 82/100\n",
            "81/81 [==============================] - 5s 61ms/step - loss: 8.9174e-05 - val_loss: 0.0028\n",
            "Epoch 83/100\n",
            "81/81 [==============================] - 5s 66ms/step - loss: 9.7929e-05 - val_loss: 6.1566e-04\n",
            "Epoch 84/100\n",
            "81/81 [==============================] - 6s 70ms/step - loss: 9.4280e-05 - val_loss: 3.7232e-04\n",
            "Epoch 85/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 9.0592e-05 - val_loss: 4.3444e-04\n",
            "Epoch 86/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 1.0036e-04 - val_loss: 0.0025\n",
            "Epoch 87/100\n",
            "81/81 [==============================] - 5s 66ms/step - loss: 9.8838e-05 - val_loss: 4.4835e-04\n",
            "Epoch 88/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 9.7466e-05 - val_loss: 4.2506e-04\n",
            "Epoch 89/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 9.5477e-05 - val_loss: 9.9687e-04\n",
            "Epoch 90/100\n",
            "81/81 [==============================] - 6s 71ms/step - loss: 8.9480e-05 - val_loss: 0.0018\n",
            "Epoch 91/100\n",
            "81/81 [==============================] - 5s 65ms/step - loss: 1.0212e-04 - val_loss: 6.0829e-04\n",
            "Epoch 92/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 8.9553e-05 - val_loss: 0.0012\n",
            "Epoch 93/100\n",
            "81/81 [==============================] - 6s 74ms/step - loss: 8.8354e-05 - val_loss: 4.3243e-04\n",
            "Epoch 94/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 1.0094e-04 - val_loss: 0.0011\n",
            "Epoch 95/100\n",
            "81/81 [==============================] - 6s 75ms/step - loss: 9.2200e-05 - val_loss: 0.0012\n",
            "Epoch 96/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 9.9641e-05 - val_loss: 0.0019\n",
            "Epoch 97/100\n",
            "81/81 [==============================] - 6s 74ms/step - loss: 9.8888e-05 - val_loss: 3.8188e-04\n",
            "Epoch 98/100\n",
            "81/81 [==============================] - 5s 62ms/step - loss: 9.8071e-05 - val_loss: 3.9303e-04\n",
            "Epoch 99/100\n",
            "81/81 [==============================] - 5s 63ms/step - loss: 8.6285e-05 - val_loss: 4.3888e-04\n",
            "Epoch 100/100\n",
            "81/81 [==============================] - 6s 73ms/step - loss: 9.6016e-05 - val_loss: 7.9945e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f06121b38e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 b\n",
        "1. Define an LSTM model architecture using Keras.\n",
        "2. Compile the model with an appropriate optimizer and loss function.\n",
        "3. Fit the model to the training data."
      ],
      "metadata": {
        "id": "Nhg1NgSiWZGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5c.  Generate me the code to predict the future stock returns of AAPL using historical price data and an LSTM model in TensorFlow and Keras. Could you thoroughly explain to me the process of developing the LSTM model architecture and the necessary steps for preprocessing, training, and evaluating the model?\""
      ],
      "metadata": {
        "id": "6t0SfO0KWbfP"
      }
    }
  ]
}